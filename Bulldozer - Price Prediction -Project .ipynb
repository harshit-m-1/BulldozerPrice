{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963a3ba9",
   "metadata": {},
   "source": [
    "##  ðŸšš Predicting the Sale Price of Bulldozers using Machine Learning\n",
    "\n",
    "\n",
    "In this notebook, we're going to go through an example machine learning project with the goal of predicting the sale price of bulldozers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c26b8",
   "metadata": {},
   "source": [
    "## 1. Problem defition\n",
    "\n",
    "How well can we predict the future sale price of a bulldozer, given its characteristics and previous examples of how much      similar bulldozers have been sold for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129cbcc1",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "The data is downloaded from the Kaggle Bluebook for Bulldozers competition: https://www.kaggle.com/c/bluebook-for-bulldozers/data\n",
    "\n",
    "1. There are 3 main datasets:\n",
    "2. Train.csv is the training set, which contains data through the end of 2011.\n",
    "   Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set  throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "   \n",
    "   \n",
    "  3. Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 -    November 2012. Your score on the test set determines your final rank for the competition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828419f8",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n",
    "\n",
    "For more on the evaluation of this project check: https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation\n",
    "\n",
    "Note: The goal for most regression evaluation metrics is to minimize the error. For example, our goal for this project will be to build a machine learning model which minimises RMSLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09417adc",
   "metadata": {},
   "source": [
    "## 4. Features\n",
    "Kaggle provides a data dictionary detailing all of the features of the dataset. You can view this data dictionary on Google Sheets: https://docs.google.com/spreadsheets/d/18ly-bLR8sbDJLITkWG7ozKm8l3RyieQ2Fpgix-beSYI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6a812e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _cext: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:276\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 276\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:270\u001b[0m, in \u001b[0;36m_check_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ft2font  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modname, minver \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    264\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcycler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.10\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    265\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateutil\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.7\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    268\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyparsing\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    269\u001b[0m ]:\n\u001b[1;32m--> 270\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m                           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kiwisolver\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2013-2022, Nucleic Development Team.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# The full license is in the file LICENSE, distributed with this software.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     Constraint,\n\u001b[0;32m     10\u001b[0m     Expression,\n\u001b[0;32m     11\u001b[0m     Solver,\n\u001b[0;32m     12\u001b[0m     Term,\n\u001b[0;32m     13\u001b[0m     Variable,\n\u001b[0;32m     14\u001b[0m     __kiwi_version__,\n\u001b[0;32m     15\u001b[0m     __version__,\n\u001b[0;32m     16\u001b[0m     strength,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     BadRequiredStrength,\n\u001b[0;32m     20\u001b[0m     DuplicateConstraint,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     UnsatisfiableConstraint,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBadRequiredStrength\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicateConstraint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__kiwi_version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m ]\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _cext: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imort traiining amd validation sets \n",
    "df=pd.read_csv(\"TrainAndValid.csv\",\n",
    "              low_memory = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots()\n",
    "ax.scatter(df[\"saledate\"][:1000],df[\"SalePrice\"][:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice.plot.hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89edb52",
   "metadata": {},
   "source": [
    "### Parsing Dates\n",
    "\n",
    "When we work with timw and data we want to enrich the time and date component as much as possible .\n",
    "\n",
    "we can do that by telling pandas which of our column has dates in it using then past_dates parametere "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data again but this time parse dates\n",
    "df=pd.read_csv(\"TrainAndValid.csv\",\n",
    "              low_memory = False ,\n",
    "              parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377359fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ab15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig,ax= plt.subplots()\n",
    "ax.scatter(df[\"saledate\"][:1000],df[\"SalePrice\"][:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f848d",
   "metadata": {},
   "source": [
    "### Sort Data frame by saledate \n",
    "\n",
    "When working with time searies data, its good idea to sort it by date ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort  dataframe in date order\n",
    "df.sort_values(by=[\"saledate\"],inplace=True,ascending= True )\n",
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b0b58",
   "metadata": {},
   "source": [
    "### Make a copy of orignal DataFrame \n",
    "we make a copy of the orignal dataframe so when we manupulate the copy ,we've still got out orignal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70354ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a copy \n",
    "df_tmp= df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101e12b",
   "metadata": {},
   "source": [
    "## Add datetime parametere for 'saledate' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62838ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"saleYear\"]=df_tmp.saledate.dt.year\n",
    "df_tmp[\"saleMonth\"]=df_tmp.saledate.dt.month \n",
    "df_tmp[\"saleDay\"]=df_tmp.saledate.dt.day\n",
    "df_tmp[\"saleDayofweek\"]=df_tmp.saledate.dt.dayofweek\n",
    "df_tmp[\"saleDayofYear\"]=df_tmp.saledate.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the value of diffferent columns \n",
    "df_tmp.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abaf34",
   "metadata": {},
   "source": [
    "## 5. Modeling \n",
    "\n",
    "we ve  done through EDA (we could always do more ) but lets start to do some model driven EDA ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc59bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# #Lets build a machine learning model (check machine learning map to select model )\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# model=RandomForestRegressor(n_jobs=1,\n",
    "#                             random_state=42)\n",
    "\n",
    "# model.fit(df_tmp.drop(\"SalePrice\",axis=1),df_tmp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE ABOVE ERROR IS BECAUSE OF ALL THE DATA IS NOT NUMERIC AND ALSO WE HAVE MISSING VALUE ^^^\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d04840",
   "metadata": {},
   "source": [
    "### Convert strings to categories \n",
    "\n",
    "One way we can turn all of our data into numbersd is by converting them to pandas categories ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a521297",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_string_dtype(df_tmp[\"UsageBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239689c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the colums which contains strings\n",
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d80352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're wondering what df.items() does, here's an example\n",
    "random_dict = {\"key1\": \"hello\",\n",
    "               \"key2\": \"world!\"}\n",
    "\n",
    "for key, value in random_dict.items():\n",
    "    print(f\"this is a key: {key}\",\n",
    "          f\"this is a value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf325420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will turn all of the string value into category values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_tmp[label] = content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a570872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dcbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing data\n",
    "df_tmp.isnull().sum()/len(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89947672",
   "metadata": {},
   "source": [
    "## Save Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57dfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export current tmp dataframe\n",
    "df_tmp.to_csv(\"train_tmp.csv\",\n",
    "              index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc65b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import preprocessed data\n",
    "df_tmp = pd.read_csv(\"train_tmp.csv\",\n",
    "                     low_memory=False)\n",
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24df8e",
   "metadata": {},
   "source": [
    "## Fill missing values \n",
    "\n",
    "### Fill numeric missing values first \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca242c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tmp.ModelID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which numeric columns have null values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf73e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numeric rows with the median\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            # Add a binary column which tells us if the data was missing or not\n",
    "            df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            # Fill missing numeric values with median\n",
    "            df_tmp[label] = content.fillna(content.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02011ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how median is more robust than mean\n",
    "hundreds = np.full((1000,), 100)\n",
    "hundreds_billion = np.append(hundreds, 1000000000)\n",
    "np.mean(hundreds), np.mean(hundreds_billion), np.median(hundreds), np.median(hundreds_billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831734be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's any null numeric values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb22fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how many examples were missing\n",
    "df_tmp.auctioneerID_is_missing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77491ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd869829",
   "metadata": {},
   "source": [
    "### Filling and turning catrgotical variable into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns which aren't numeric\n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn categorical variables into numbers and fill missing\n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        # Add binary column to indicate whether sample had missing value\n",
    "        df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "        # Turn categories into numbers and add +1\n",
    "        df_tmp[label] = pd.Categorical(content).codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_tmp[\"state\"]).codes+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fa41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0414124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c5880",
   "metadata": {},
   "source": [
    "Now that all of data is numeric as well as our dataframe has no missing values, we should be able to build a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Instantiate model\n",
    "# model = RandomForestRegressor(n_jobs=-1,\n",
    "#                               random_state=42)\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(df_tmp.drop(\"SalePrice\", axis=1), df_tmp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORE THE MODEL \n",
    "model.score(df_tmp.drop(\"SalePrice\", axis=1), df_tmp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb93899",
   "metadata": {},
   "source": [
    "Question: Why doesn't the above metric hold water? (why isn't the metric reliable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413593d",
   "metadata": {},
   "source": [
    "## Splitting data into train/valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998b56a",
   "metadata": {},
   "source": [
    "According to the Kaggle data page, the validation set and test set are split according to dates.\n",
    "\n",
    "This makes sense since we're working on a time series problem.\n",
    "\n",
    "E.g. using past events to try and predict future events.\n",
    "\n",
    "Knowing this, randomly splitting our data into train and test sets using something like train_test_split() wouldn't work.\n",
    "\n",
    "Instead, we split our data into training, validation and test sets using the date each sample occured.\n",
    "\n",
    "In our case:\n",
    "\n",
    "### 1- Training = all samples up until 2011\n",
    "### 2- Valid = all samples form January 1, 2012 - April 30, 2012\n",
    "### 3- Test = all samples from May 1, 2012 - November 2012\n",
    "\n",
    "For more on making good training, validation and test sets, check out the post How (and why) to create a good validation set by Rachel Thomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tmp.saleYear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f26618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation\n",
    "df_val = df_tmp[df_tmp.saleYear == 2012]\n",
    "df_train = df_tmp[df_tmp.saleYear != 2012]\n",
    "\n",
    "len(df_val), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ed04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X & y\n",
    "X_train, y_train = df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\n",
    "X_valid, y_valid = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c0ba8",
   "metadata": {},
   "source": [
    "Building an evaluation function\n",
    "According to Kaggle for the Bluebook for Bulldozers competition, the evaluation function they use is root mean squared log error (RMSLE).\n",
    "\n",
    "RMSLE = generally you don't care as much if you're off by $10 as much as you'd care if you were off by 10%, you care more about ratios rather than differences. MAE (mean absolute error) is more about exact differences.\n",
    "\n",
    "It's important to understand the evaluation metric you're going for.\n",
    "\n",
    "Since Scikit-Learn doesn't have a function built-in for RMSLE, we'll create our own.\n",
    "\n",
    "We can do this by taking the square root of Scikit-Learn's mean_squared_log_error (MSLE). MSLE is the same as taking the log of mean squared error (MSE).\n",
    "\n",
    "We'll also calculate the MAE and R^2 for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation function (the competition uses Root Mean Square Log Error)\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
    "\n",
    "def rmsle(y_test, y_preds):\n",
    "    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n",
    "\n",
    "# Create function to evaluate our model\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_valid)\n",
    "    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n",
    "              \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n",
    "              \"Training RMSLE\": rmsle(y_train, train_preds),\n",
    "              \"Valid RMSLE\": rmsle(y_valid, val_preds),\n",
    "              \"Training R^2\": model.score(X_train, y_train),\n",
    "              \"Valid R^2\": model.score(X_valid, y_valid)}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0fdfe",
   "metadata": {},
   "source": [
    "### Testing our model on a subset (to tune the hyperparameters)\n",
    "Retraing an entire model would take far too long to continuing experimenting as fast as we want to.\n",
    "\n",
    "So what we'll do is take a sample of the training set and tune the hyperparameters on that before training a larger model.\n",
    "\n",
    "If you're experiments are taking longer than 10-seconds (give or take how long you have to wait), you should be trying to speed things up. You can speed things up by sampling less data or using a faster computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc634989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes too long...\n",
    "\n",
    "# %%time\n",
    "# # Retrain a model on training data\n",
    "# model.fit(X_train, y_train)\n",
    "# show_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aefa04c",
   "metadata": {},
   "source": [
    "Depending on your computer (mine is a MacBook Pro), making calculations on ~400,000 rows may take a while...\n",
    "\n",
    "Let's alter the number of samples each n_estimator in the RandomForestRegressor see's using the max_samples parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change max samples in RandomForestRegressor\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                              max_samples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2635e38",
   "metadata": {},
   "source": [
    "Setting max_samples to 10000 means every n_estimator (default 100) in our RandomForestRegressor will only see 10000 random samples from our DataFrame instead of the entire 400,000.\n",
    "\n",
    "In other words, we'll be looking at 40x less samples which means we'll get faster computation speeds but we should expect our results to worsen (simple the model has less samples to learn patterns from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b773edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cutting down the max number of samples each tree can see improves training time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58a328",
   "metadata": {},
   "source": [
    "### In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "### On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dd16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d54f9",
   "metadata": {},
   "source": [
    "#### Beautiful, that took far less time than the model with all the data.\n",
    "\n",
    "With this, let's try tune some hyperparameters.\n",
    "\n",
    "Hyperparameter tuning with RandomizedSearchCV\n",
    "You can increase n_iter to try more combinations of hyperparameters but in our case, we'll try 20 and see where it gets us.\n",
    "\n",
    "Remember, we're trying to reduce the amount of time it takes between experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Different RandomForestClassifier hyperparameters\n",
    "rf_grid = {\"n_estimators\": np.arange(10, 100, 10),\n",
    "           \"max_depth\": [None, 3, 5, 10],\n",
    "           \"min_samples_split\": np.arange(2, 20, 2),\n",
    "           \"min_samples_leaf\": np.arange(1, 20, 2),\n",
    "           \"max_features\": [0.5, 1.0, \"sqrt\"], # Note: \"max_features='auto'\" is equivalent to \"max_features=1.0\", as of Scikit-Learn version 1.1\n",
    "           \"max_samples\": [10000]}\n",
    "\n",
    "rs_model = RandomizedSearchCV(RandomForestRegressor(),\n",
    "                              param_distributions=rf_grid,\n",
    "                              n_iter=20,\n",
    "                              cv=5,\n",
    "                              verbose=True)\n",
    "\n",
    "rs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb35171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters from the RandomizedSearch \n",
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the RandomizedSearch model\n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246db6f",
   "metadata": {},
   "source": [
    "### Train a model with the best parameters\n",
    "In a model I prepared earlier, I tried 100 different combinations of hyperparameters (setting n_iter to 100 in RandomizedSearchCV) and found the best results came from the ones you see below.\n",
    "\n",
    "Note: This kind of search on my computer (n_iter = 100) took ~2-hours. So it's kind of a set and come back later experiment.\n",
    "\n",
    "We'll instantiate a new model with these discovered hyperparameters and reset the max_samples back to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3121c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Most ideal hyperparameters\n",
    "ideal_model = RandomForestRegressor(n_estimators=90,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_samples_split=14,\n",
    "                                    max_features=0.5,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_samples=None)\n",
    "ideal_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_scores(ideal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ca0a7",
   "metadata": {},
   "source": [
    "With these new hyperparameters as well as using all the samples, we can see an improvement to our models performance.\n",
    "\n",
    "You can make a faster model by altering some of the hyperparameters. Particularly by lowering n_estimators since each increase in n_estimators is basically building another small model.\n",
    "\n",
    "However, lowering of n_estimators or altering of other hyperparameters may lead to poorer results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Faster model\n",
    "fast_model = RandomForestRegressor(n_estimators=40,\n",
    "                                   min_samples_leaf=3,\n",
    "                                   max_features=0.5,\n",
    "                                   n_jobs=-1)\n",
    "fast_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e364b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(fast_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52811d",
   "metadata": {},
   "source": [
    "### Make predictions on test data\n",
    "Now we've got a trained model, it's time to make predictions on the test data.\n",
    "\n",
    "Remember what we've done.\n",
    "\n",
    "Our model is trained on data prior to 2011. However, the test data is from May 1 2012 to November 2012.\n",
    "\n",
    "So what we're doing is trying to use the patterns our model has learned in the training data to predict the sale price of a Bulldozer with characteristics it's never seen before but are assumed to be similar to that of those in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Test.csv\",\n",
    "                      parse_dates=[\"saledate\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c17df",
   "metadata": {},
   "source": [
    "\n",
    "Ahhh... the test data isn't in the same format of our other data, so we have to fix it. Let's create a function to preprocess our data.\n",
    "\n",
    "### Preprocessing the test data\n",
    "Our model has been trained on data formatted in the same way as the training data.\n",
    "\n",
    "This means in order to make predictions on the test data, we need to take the same steps we used to preprocess the training data to preprocess the test data.\n",
    "\n",
    "Remember: Whatever you do to the training data, you have to do to the test data.\n",
    "\n",
    "Let's create a function for doing so (by copying the preprocessing steps we used above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e10fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Performs transformations on df and returns transformed df.\n",
    "    \"\"\"\n",
    "    df[\"saleYear\"] = df.saledate.dt.year\n",
    "    df[\"saleMonth\"] = df.saledate.dt.month\n",
    "    df[\"saleDay\"] = df.saledate.dt.day\n",
    "    df[\"saleDayOfweek\"] = df.saledate.dt.dayofweek\n",
    "    df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n",
    "    \n",
    "    df.drop(\"saledate\", axis=1, inplace=True)\n",
    "    \n",
    "    # Fill the numeric rows with median\n",
    "    for label, content in df.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            if pd.isnull(content).sum():\n",
    "                # Add a binary column which tells us if the data was missing or not\n",
    "                df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "                # Fill missing numeric values with median\n",
    "                df[label] = content.fillna(content.median())\n",
    "    \n",
    "        # Filled categorical missing data and turn categories into numbers\n",
    "        if not pd.api.types.is_numeric_dtype(content):\n",
    "            df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            # We add +1 to the category code because pandas encodes missing categories as -1\n",
    "            df[label] = pd.Categorical(content).codes+1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0acb131",
   "metadata": {},
   "source": [
    "Question: Where would this function break?\n",
    "\n",
    "Hint: What if the test data had different missing values to the training data?\n",
    "\n",
    "Now we've got a function for preprocessing data, let's preprocess the test dataset into the same format as our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1956d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = preprocess_data(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05daffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on updated test data\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f4ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2a586",
   "metadata": {},
   "source": [
    "We've found an error and it's because our test dataset (after preprocessing) has 101 columns where as, our training dataset (X_train) has 102 columns (after preprocessing).\n",
    "\n",
    "Let's find the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9078bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find how the columns differ using sets\n",
    "set(X_train.columns) - set(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2de98",
   "metadata": {},
   "source": [
    "In this case, it's because the test dataset wasn't missing any auctioneerID fields.\n",
    "\n",
    "To fix it, we'll add a column to the test dataset called auctioneerID_is_missing and fill it with False, since none of the auctioneerID fields are missing in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f96f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match test dataset columns to training dataset\n",
    "df_test[\"auctioneerID_is_missing\"] = False\n",
    "df_test=df_test.reindex(columns=list(X_train.columns))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a181e985",
   "metadata": {},
   "source": [
    "There's one more step we have to do before we can make predictions on the test data.\n",
    "\n",
    "And that's to line up the columns (the features) in our test dataset to match the columns in our training dataset.\n",
    "\n",
    "As in, the order of the columnns in the training dataset, should match the order of the columns in our test dataset.\n",
    "\n",
    "Note: As of Scikit-Learn 1.2, the order of columns that were fit on should match the order of columns that are predicted on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7e544",
   "metadata": {},
   "source": [
    "Now the test dataset column names and column order matches the training dataset, we should be able to make predictions on it using our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3189f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset using the best model\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbd017",
   "metadata": {},
   "source": [
    "When looking at the Kaggle submission requirements, we see that if we wanted to make a submission, the data is required to be in a certain format. Namely, a DataFrame containing the SalesID and the predicted SalePrice of the bulldozer.\n",
    "\n",
    "Let's make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c405be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame compatible with Kaggle submission requirements\n",
    "df_preds = pd.DataFrame()\n",
    "df_preds[\"SalesID\"] = df_test[\"SalesID\"]\n",
    "df_preds[\"SalePrice\"] = test_preds\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv...\n",
    "#df_preds.to_csv(\"../data/bluebook-for-bulldozers/predictions.csv\",\n",
    "#                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d209e0e",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Since we've built a model which is able to make predictions. The people you share these predictions with (or yourself) might be curious of what parts of the data led to these predictions.\n",
    "\n",
    "This is where feature importance comes in. Feature importance seeks to figure out which different attributes of the data were most important when it comes to predicting the target variable.\n",
    "\n",
    "In our case, after our model learned the patterns in the data, which bulldozer sale attributes were most important for predicting its overall sale price?\n",
    "\n",
    "Beware: the default feature importances for random forests can lead to non-ideal results.\n",
    "\n",
    "To find which features were most important of a machine learning model, a good idea is to search something like \"[MODEL NAME] feature importance\".\n",
    "\n",
    "Doing this for our RandomForestRegressor leads us to find the feature_importances_ attribute.\n",
    "\n",
    "Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c71f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find feature importance of our best model\n",
    "ideal_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting feature importance\n",
    "def plot_features(columns, importances, n=20):\n",
    "    df = (pd.DataFrame({\"features\": columns,\n",
    "                        \"feature_importances\": importances})\n",
    "          .sort_values(\"feature_importances\", ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    # Plot the dataframe\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n",
    "    ax.set_ylabel(\"Features\")\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ec4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns, ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Enclosure\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832e8d3",
   "metadata": {},
   "source": [
    "Question to finish: Why might knowing the feature importances of a trained machine learning model be helpful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35931cf7",
   "metadata": {},
   "source": [
    "To do Process: What other machine learning models could you try on our dataset? Hint: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html check out the regression section of this map, or try to look at something like CatBoost.ai or XGBooost.ai."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
